<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: bash | Bits, Bytes, and Words]]></title>
  <link href="https://blog.jez.io/categories/bash/atom.xml" rel="self"/>
  <link href="https://blog.jez.io/"/>
  <updated>2021-05-29T04:52:10-04:00</updated>
  <id>https://blog.jez.io/</id>
  <author>
    <name><![CDATA[Jake Zimmerman]]></name>
    <email><![CDATA[jake@zimmerman.io]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Surgery on Code from the Command Line]]></title>
    <link href="https://blog.jez.io/surgery-on-code/"/>
    <updated>2019-07-30T09:32:48-07:00</updated>
    <id>https://blog.jez.io/surgery-on-code</id>
    <content type="html"><![CDATA[<p>I&rsquo;m frequently faced wth problems like &ldquo;find and replace this pattern,
but only on specific lines,&rdquo; especially lines that have type errors on
them. I&rsquo;ve built three new CLI tools that fit the need to operate on a
specific set of lines in a codebase. In this post I&rsquo;ll walk through a
couple examples to show them in action.</p>

<!-- more -->


<p>For the impatient, the tools that I&rsquo;ve built are:</p>

<ul>
<li><p><a href="https://github.com/jez/multi-grep"><code>multi-grep</code></a></p>

<p>Like <code>grep</code>, but search for a pattern only at the specified
locations, printing the locations where a match was found.</p></li>
<li><p><a href="https://github.com/jez/multi-sub"><code>multi-sub</code></a></p>

<p>Substitute a pattern with a replacement at the specified locations,
editing the file in place.</p></li>
<li><p><a href="https://github.com/jez/diff-locs"><code>diff-locs</code></a></p>

<p>Convert a unified diff (like the output of <code>git diff</code>) into a list
of locations affected by that diff.</p></li>
</ul>


<p>With the quick intros out of the way, let&rsquo;s dive into some examples.</p>

<h2><code>multi-grep</code></h2>

<p>Consider the file <code>locs.txt</code> below which is a list of <code>filename:line</code>
pairs:</p>

<pre><code class="plain locs.txt">file_a.txt:13
file_a.txt:22
file_a.txt:79
file_b.txt:10
file_b.txt:11
</code></pre>

<p>(I call such <code>filename:line</code> pairs &ldquo;locations&rdquo; or &ldquo;locs.&rdquo;)</p>

<p>Also consider that our project is huge, and has many more files
than just <code>file_a.txt</code> and <code>file_b.txt</code>. To filter the <code>locs.txt</code> list
to only the lines that contain the pattern &ldquo;hello&rdquo;, we can use
<code>multi-grep</code>:</p>

<pre><code class="bash">‚ùØ multi-grep 'hello' locs.txt
file_a.txt:13
file_b.txt:10
</code></pre>

<p>The output means that only line 13 in <code>file_a.txt</code> and line 10 in
<code>file_b.txt</code> contain <code>hello</code>, given our initial set of 5 locs. The
search completely ignored all other files in the project because they
weren&rsquo;t mentioned in <code>locs.txt</code>. Searching with <code>multi-grep</code> scales with
the size of the input list, not with the size of the codebase being
searched.</p>

<p>This was a contrived example, but let&rsquo;s keep plowing forward with the
basics so we can apply them to a real example.</p>

<h2><code>multi-sub</code></h2>

<p>If <code>multi-grep</code> is like <code>grep</code>, <code>multi-sub</code> is like <code>sed</code> but with only
the substitute command (<code>s/find/replace/</code>). Taking our previous example,
<code>multi-sub</code> finds and replaces a pattern on specific input lines:</p>

<pre><code class="bash">‚ùØ multi-sub 'hello' 'goodbye' locs.txt
# ... file_a.txt:13 edited: s/hello/goodbye/ ...
# ... file_b.txt:10 edited: s/hello/goodbye/ ...
</code></pre>

<p>In our previous example, only locations <code>file_a.txt:13</code> and
<code>file_b.txt:10</code> matched the pattern <code>hello</code>. So after running this
<code>multi-sub</code> command, those two files will be updated in place. On both
lines, <code>hello</code> will be replaced with <code>goodbye</code>.</p>

<h2>A larger example</h2>

<p>With the basics out of the way, let&rsquo;s tackle a real-world problem. I
work with the output of <a href="https://sorbet.org">Sorbet</a> a lot, so I&rsquo;ve used it for this next
example (Sorbet is a type checker for Ruby). When Sorbet detects type
errors in a program, it generates output like this:</p>

<pre><code>test/payment_methods/update.rb:648: Method `[]` does not exist on `NilClass` component of `T.nilable(T::Hash[T.untyped, T.untyped])` http://go/e/7003
     648 |   assert_equal(nil, previous['billing_details']['address']['line1'])
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^

test/payment_methods/update.rb:649: Method `[]` does not exist on `NilClass` component of `T.nilable(T::Hash[T.untyped, T.untyped])` http://go/e/7003
     649 |   assert_equal(nil, previous['card']['checks']['address_line1_check'])
                               ^^^^^^^^^^^^^^^^

test/payment_methods/webhooks.rb:610: Method `[]` does not exist on `NilClass` component of `T.nilable(T::Hash[T.untyped, T.untyped])` http://go/e/7003
     610 |   assert_equal(2, notification['card']['exp_month'])
                             ^^^^^^^^^^^^^^^^^^^^

... many more errors ...

Errors: 253
</code></pre>

<p>The error messages look a lot better with colors! If you don&rsquo;t believe
me, you can <a href="https://sorbet.run">try Sorbet in the browser</a> and see for
yourself.</p>

<p>The example above is inspired by real output that we saw at Stripe while
iterating on Sorbet. In this specific case, one of my coworkers had
improved Sorbet to track more information statically, which uncovered a
bunch of new type errors.</p>

<p>On the Sorbet team, we have a policy that before landing changes like
this, we modify Stripe&rsquo;s monorepo to preemptively silence the new
errors. Jordan Brown has a great article on the <a href="https://medium.com/flow-type/upgrading-flow-codebases-40ef8dd3ccd8">Flow blog</a> justifying
this technique, so I&rsquo;ll skip the why and focus only on how to carry out
codemods like this.</p>

<p>As seen above, Sorbet error output always looks like
<code>filename.rb:line:Error message</code>. With a little massaging, this will
feed directly into <code>multi-sub</code>. Also notice that on the lines with
errors, the file contents always looked something like this:</p>

<pre><code class="ruby">foo['bar']
</code></pre>

<p>To tell Sorbet to silence the errors on these lines, we&rsquo;ll need to wrap
the variable in a call to <code>T.unsafe(...)</code>:</p>

<pre><code class="ruby">T.unsafe(foo)['bar']
</code></pre>

<p>This instructs to Sorbet to <a href="https://sorbet.org/docs/troubleshooting#escape-hatches">forget all static type
information</a> about the variable, thus silencing the error.
The key is to only perform this edit on lines with errors&mdash;
we&rsquo;d hate to needlessly throw away type information by changing
unrelated lines! For things like this, <code>grep</code> and <code>sed</code> are often too
coarse-grained, because accessing a hash like this in Ruby is abundantly
common.</p>

<p>With <code>multi-sub</code>, we can write a really simple regex targetting these
hash lookups, but scope the regex to only lines in the error output:</p>

<pre><code class="bash"># (1) Type check the project
‚ùØ srb tc 2&gt;&amp;1 | \
  # (2) Filter the error output to only have the top-level error lines
  sed -e '/^ /d; /^$/d; /^Errors:/d' | \
  # (3) Chop off the error message, keeping only the filename:line
  cut -d : -f 1-2 | \
  # (4) Use multi-sub to replace things like foo[ with T.unsafe(foo)[
  multi-sub '\([a-zA-Z0-9_]+\)\[' 'T.unsafe(\1)['
</code></pre>

<p>Take a look through the four steps in the bash oneliner above:</p>

<ol>
<li>Type check the project, then</li>
<li>filter out every line that doesn&rsquo;t have a location, then</li>
<li>chop of the error messages, and finally</li>
<li>use <code>multi-sub</code> to perform the substitution.</li>
</ol>


<p>The net result is to update the files in place, performing the
substitution only on the lines with errors. Altogether once more, but on
one line, making use of a shell alias that I have to abbreviate the
inner two steps:</p>

<pre><code class="bash">‚ùØ srb tc 2&gt;&amp;1 | onlylocs | multi-sub '\([a-zA-Z0-9_]+\)\[' 'T.unsafe(\1)['
</code></pre>

<p>So with a super short bash oneliner, we&rsquo;ve done a mass codemod that
fixes hundreds of errors at once, without having to silence more than
necessary.</p>

<p>If <code>grep</code> and <code>sed</code> are like chainsaws, I like to think of <code>multi-grep</code>
and <code>multi-sub</code> like scalpels&mdash;ideal for performing surgery on a
codebase. Regular expressions are often super imprecise tools for
codemods. But by scoping down the regex to run only on specific lines,
it doesn&rsquo;t matter. The added precision from explicit locations makes up
for how blunt regular expressions are.</p>

<h2><code>diff-locs</code></h2>

<p>I&rsquo;ve built one more command in the same spirit as <code>multi-grep</code> and
<code>multi-sub</code>, except that instead of consuming locations, it emits them.
Specifically, given a diff it outputs one <code>filename:line</code> pair for every
line that was affected by the diff.<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup> It&rsquo;s ideal for consuming the
output of <code>git show</code> or <code>git diff</code>:</p>

<pre><code>‚ùØ git show HEAD | diff-locs
test/payment_methods/update.rb:648
test/payment_methods/update.rb:649
test/payment_methods/webhooks.rb:610
</code></pre>

<p>I frequently use <code>diff-locs</code> to tweak codemods that I&rsquo;ve already
committed. For example, we could go back and add a TODO comment above
each new <code>T.unsafe</code> call:</p>

<pre><code class="bash"># (1) Generate a diff from git
‚ùØ git show HEAD | \
  # (2) Convert the diff to a list of locations
  diff-locs | \
  # (3) Use multi-sub to insert a comment before each line
  multi-sub '^\( *\)' $'\\1# TODO: Unsilence this error\n\\1'
</code></pre>

<p>Recapping the pipeline above:</p>

<ol>
<li>Use <code>git show</code> to generate a diff, then</li>
<li>convert the diff to a list of locations with <code>diff-locs</code>, and finally</li>
<li>insert a comment before each location with <code>multi-sub</code>.</li>
</ol>


<p><code>diff-locs</code> is particularly handy because after the first codemod, there
won&rsquo;t be type errors anymore! So to get a list of locations to perform
the edit on, we&rsquo;d have had to check out the commit before fixing the
errors, save the list of errors to a file, go back, and finally do the
edit we wanted to in the first place.</p>

<p>Instead, we can take advantage of the fact that all that information is
already stored in git history, skipping a bunch of steps. (And asking
git to show a diff is way faster than asking Sorbet to re-typecheck a
whole project üòÖ)</p>

<h2>Aside: The implementations</h2>

<p>One thing I&rsquo;d like to point out is that I took some care to make sure
these commands weren&rsquo;t eggregiously slow. I prototyped these commands
with some hacky scripts, but after doing some rather large codemods I
got annoyed with them taking minutes to finish.</p>

<p>Some things that make these new commands fast:</p>

<ul>
<li><code>multi-grep</code> and <code>multi-sed</code> re-use an already opened file to avoid
reading extra information.</li>
<li><code>multi-grep</code> is written in Standard ML, <code>multi-sub</code> is written in
OCaml, and <code>diff-locs</code> is written in Haskell&mdash;all languages which
have great optimizing compilers. This means much better performance
than a scripting language.</li>
</ul>


<p>If you&rsquo;re curious, you can read through their implementations on GitHub:</p>

<ul>
<li><a href="https://github.com/jez/multi-grep"><code>multi-grep</code></a></li>
<li><a href="https://github.com/jez/multi-sub"><code>multi-sub</code></a></li>
<li><a href="https://github.com/jez/diff-locs"><code>diff-locs</code></a></li>
</ul>


<p>As always if you have questions or notice issues please don&rsquo;t hesitate
to reach out!</p>

<!-- vim:tw=72
-->

<div class="footnotes">
<hr/>
<ol>
<li id="fn:1">
<p>It defaults to only lines affected after the diff applies, but there&rsquo;s an option to make it show both added and removed lines.<a href="#fnref:1" rev="footnote">&#8617;</a></p></li>
</ol>
</div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[A Debugger for Bash in Six Lines of Bash]]></title>
    <link href="https://blog.jez.io/bash-debugger/"/>
    <updated>2019-06-16T09:25:06-07:00</updated>
    <id>https://blog.jez.io/bash-debugger</id>
    <content type="html"><![CDATA[<p>I implemented a &ldquo;debugger&rdquo; for Bash in six lines of Bash. It kind of
behaves like JavaScript&rsquo;s <code>debugger</code> keyword. Here&rsquo;s how it works:</p>

<!-- more -->


<pre><code class="bash">debugger() {
  echo "Stopped in REPL. Press ^D to resume, or ^C to abort."
  local line
  while read -r -p "&gt; " line; do
    eval "$line"
  done
  echo
}
</code></pre>

<p>And there it is. Add this to a script, insert a call to <code>debugger</code>
somewhere, and run the script. It&rsquo;ll pause right execution right there.
Once paused, we can do things like:</p>

<ul>
<li>print the contents of variables with <code>echo</code></li>
<li>run commands that are on our <code>PATH</code> (e.g., <code>pwd</code>, <code>ls</code>, &hellip;)</li>
<li>call functions defined in the script</li>
</ul>


<p>&hellip; and pretty much everything that we could have done if we were
editing the script directly. Here&rsquo;s a short session demonstrating how it
can be used:</p>

<pre><code class="bash">#!/usr/bin/env bash

debugger() {
  # ... implemented above ...
}

foo=1
debugger
echo "foo: $foo"
</code></pre>

<pre><code>‚ùØ foo.sh
Stopped in REPL. Press ^D to resume, or ^C to abort.
&gt; pwd
/Users/jez
&gt; echo $foo
1
&gt; foo=42
&gt; ^D
foo: 42
</code></pre>

<h2>Stopping on failures</h2>

<p>I find that most of the time this is useful when a script is failing for
some reason. Rather than put a <code>debugger</code> call right before the failing
command, I can just add this at the top of the file:</p>

<pre><code class="bash">trap 'debugger' ERR
</code></pre>

<p>When any command has a non-zero exit code, Bash will run <code>debugger</code> and
pause the program.</p>

<p>I&rsquo;ve been keeping this function and <code>trap</code> call commented out at the top
of my scripts and uncommenting them when needed (It uses <code>eval</code>, which
is not the best from a security perspective, which is why it&rsquo;s commented
by default).</p>

<h2>Future work</h2>

<p>Of course, I said &ldquo;debugger&rdquo; in quotes earlier because it&rsquo;s not
<strong>really</strong> a debugger:</p>

<ul>
<li><p>Using it requires editing the script we want to debug to include these
lines, and then calling <code>debugger</code> somewhere. It doesn&rsquo;t launch an
inferior process and control it, like <code>gdb</code> or <code>lldb</code> would.</p></li>
<li><p>There&rsquo;s no <code>break</code> command to edit breakpoints while stopped. All
breakpoints must have been written into the program up front.</p></li>
<li><p>There&rsquo;s also no <code>step</code> or <code>next</code> commands for stepping into or over
the next function or command.</p></li>
<li><p>When it stops, it doesn&rsquo;t show the text content of the last line that
executed, or even the line number.</p></li>
</ul>


<p>But I have some thoughts on how to implement these, too&hellip; Bash&rsquo;s <code>trap</code>
builtin has a way to trap <code>DEBUG</code>, which runs after every command. I
think I could make clever use of <code>trap</code>s to implementat least one of
<code>step</code> or <code>next</code>, and definitely something that says &ldquo;stopped on line X&rdquo;
and maybe even use that to print the source text of that line.
Implementing <code>break</code> seems to be the hardest‚ÄîI don&rsquo;t have any ideas for
that one right now.</p>

<p>I&rsquo;m releasing this code into the public domain. If you want to change it
to implement any of these features, I&rsquo;d be more than interested to hear
about it!</p>

<!-- vim:tw=72
-->

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Improving CLIs with isatty]]></title>
    <link href="https://blog.jez.io/cli-tty/"/>
    <updated>2019-06-11T12:17:59-07:00</updated>
    <id>https://blog.jez.io/cli-tty</id>
    <content type="html"><![CDATA[<p>One thing I like to do to improve the command-line programs I maintain
is to make them aware of whether they&rsquo;re being run interactively. In
this post I&rsquo;ll show off an easy trick to make programs running
interactively more usable.</p>

<!-- more -->


<p>This always used to trip me up when I was first learning to use the
terminal:</p>

<pre><code class="bash">‚ùØ grep 'def foo'
</code></pre>

<p>I&rsquo;d drop this into the command-line and what happens? It hangs&hellip; Is it
because it&rsquo;s taking a long time to search? Nope‚ÄîI&rsquo;ve forgetten to tell
<code>grep</code> what files to search in!</p>

<p>When <code>grep</code> is given only a pattern to search for and no files to search
in, it assumes we want to search for that pattern on stdin. This is
great for shell scripts and one-liners at the command-line, but it&rsquo;s
<strong>super</strong> annoying when we&rsquo;re just grepping interactively.</p>

<p>The thing is, it&rsquo;s super easy to detect when the user might have made
this mistake: if we&rsquo;re defaulting to reading from stdin <strong>and</strong> the file
corresponding to stdin represents a terminal (more specifically, a
<a href="https://unix.stackexchange.com/questions/4126/">tty</a>). And once we&rsquo;ve detected it, we can print a helpful message.</p>

<p>Here&rsquo;s how I did it when writing <a href="https://github.com/jez/diff-locs"><code>diff-locs</code></a>, one of the command-line
programs I&rsquo;ve been working on lately:</p>

<pre><code class="haskell Check if stdin is a tty in Haskell">fileIn &lt;- case inputStyle of
  InputFromFile filename -&gt; IO.openFile filename IO.ReadMode
  InputFromStdin         -&gt; do
    isTTY &lt;- hIsTerminalDevice IO.stdin
    when isTTY $ do
      errPutStrLn "Warning: reading from stdin, which is a tty."
    return IO.stdin
</code></pre>

<p>If we&rsquo;ve been given a file explicitly, just open it. Otherwise, fall
back to reading from stdin. But first, check if <code>IO.stdin</code> is a terminal
device and when it <strong>is</strong>, print a warning.<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup> The complete file
containing the snippet above is <a href="https://github.com/jez/diff-locs/blob/743bff5cb1abb6e405b0369b195614aea6ec018d/app/Main.hs#L17-L24">on GitHub</a>.</p>

<p>I&rsquo;ve implemented <code>diff-locs</code> as a standard Unix filter‚Äîit takes input on
stdin and emits output on stdout. Normal usage looks something like
this, where we pipe <code>git diff</code> into <code>diff-locs</code>:</p>

<pre><code class="bash">‚ùØ git diff | diff-locs
</code></pre>

<p>But if someone is just playing around at the terminal (maybe, trying to
get the help output to show up), they might run <code>diff-locs</code> without
args, and then be greeted with this message:</p>

<pre><code>‚ùØ diff-locs
Warning: reading from stdin, which is a tty.
‚ñà
</code></pre>

<p>This is much better than just sitting there appearing to hang!</p>

<h2><code>isatty</code> in other languages</h2>

<p>The trick above works in pretty much every language that supports Unix
programming. Under the hood, the Haskell snippet above is powered by the
<code>isatty</code> function in the C standard library (<code>man 3 isatty</code>), which most
other languages wrap in some way. For example, three other languages I&rsquo;ve
done this in recently:</p>

<pre><code class="ruby Ruby">if STDIN.isatty?
  STDERR.puts 'Warning: reading from stdin, which is a tty.'
end
</code></pre>

<pre><code class="bash Bash">if [ -t 0 ]; then
  echo 'Warning: reading from stdin, which is a tty.' &gt;&amp;2
end
</code></pre>

<pre><code class="ocaml OCaml">if Unix.isatty Unix.stdin
then prerr_endline "Warning: reading from stdin, which is a tty."
else ()
</code></pre>

<p>And again, a quick search for <code>isatty &lt;language&gt;</code> should suffice for any
language that supports Unix programming. It&rsquo;s little things like this
that add up and make certain command-line utilities delightful to use.</p>
<div class="footnotes">
<hr/>
<ol>
<li id="fn:1">
<p>We don&rsquo;t really need to check whether the file we&rsquo;re opening is a tty. If the user managed to pass in the <em>name</em> of a tty file, they probably know what they&rsquo;re doing.<a href="#fnref:1" rev="footnote">&#8617;</a></p></li>
</ol>
</div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Standard ML in Travis&nbsp;CI]]></title>
    <link href="https://blog.jez.io/sml-travis-ci/"/>
    <updated>2019-06-04T09:26:45-07:00</updated>
    <id>https://blog.jez.io/sml-travis-ci</id>
    <content type="html"><![CDATA[<p>For one of my recent projects (<a href="https://github.com/jez/multi-grep"><code>multi-grep</code></a>) I went through the work to
get Standard ML building in Travis CI. It turned out to be not too
hard‚Äîin fact, the hardest part is already done, and I&rsquo;m happy to share
how it works.</p>

<!-- more -->


<p><a href="https://travis-ci.org/">Travis CI</a> is a service that lets a project run arbitrary code when
someone commits and pushes a change. This code can do things like make
sure the tests pass, build and publish releases, and even deploy the
code somewhere.</p>

<h2>Features</h2>

<p>The way I set up my builds for SML with Travis CI, I can:</p>

<ul>
<li>build and test with both macOS and Linux</li>
<li>build and test with both SML/NJ and MLton</li>
<li>create executables, even with SML/NJ</li>
<li>publish the resulting builds to GitHub as releases</li>
</ul>


<p>Apart from some scripts to install things on each operating system,
under the hood it&rsquo;s powered by <a href="https://github.com/jez/symbol">Symbol</a>, which is a build tool for
Standard ML I wrote which factors out most of the project-agnostic
stuff.</p>

<h2>The core setup</h2>

<p>Rather than paste the code into a snippet here and wait for it to get
out of date, see my <a href="https://github.com/jez/multi-grep"><code>multi-grep</code></a> project on GitHub for all the
up-to-date files. In total, there are three files in that repo which set
the whole thing up:</p>

<ol>
<li><a href="https://github.com/jez/multi-grep/blob/b6a42719b1ffca389556655982e6c4b7fa19c9a1/.travis.yml">.travis.yml</a> (kicks off the build)</li>
<li><a href="https://github.com/jez/multi-grep/blob/b6a42719b1ffca389556655982e6c4b7fa19c9a1/Brewfile">Brewfile</a> (deps for macOS build)</li>
<li><a href="https://github.com/jez/multi-grep/blob/b6a42719b1ffca389556655982e6c4b7fa19c9a1/tests/travis-install.sh">tests/travis-install.sh</a> (deps for Linux build)</li>
</ol>


<p>If you haven&rsquo;t used Travis CI before, you&rsquo;ll probably also want to check
out the <a href="https://docs.travis-ci.com/">Travis CI docs</a> to get a feel for how to actually set things
up, and where these pieces fit in.</p>

<p>After installing the deps on each box (like SML/NJ and MLton) and
running the tests, the command which actually builds the the whole
project is</p>

<pre><code>./symbol install
</code></pre>

<p>This command is provided by <a href="https://github.com/jez/symbol">Symbol</a>, a build tool I wrote for Standard
ML. I talk a little bit more about it in the section below.</p>

<h2>Why write a whole build tool?</h2>

<p>I mentioned above that I&rsquo;d written a build tool for Standard ML, called
<a href="https://github.com/jez/symbol">Symbol</a>. Why? It started as a shell script + <code>Makefile</code> for
<a href="https://github.com/jez/multi-grep"><code>multi-grep</code></a> and then I realized that these scripts could be useful in
any Standard ML project.</p>

<p>SML/NJ and MLton are already great compilers with their own build tools.
It&rsquo;s useful to be able to build a project with both (SML/NJ for faster
builds and a REPL, and MLton for faster compiled executables). All
Symbol really does is put SML/NJ and MLton behind a unified, very
stripped down interface. It doesn&rsquo;t try to hide that, so that it&rsquo;s still
possible to fall back to those programs for more complex workflows.</p>

<p>There&rsquo;s more information <a href="https://github.com/jez/symbol">in the README</a>, but some key points:</p>

<ul>
<li>Symbol makes it easy to build and install executables, even with
SML/NJ which traditionally uses heap images.</li>
<li>Symbol is built on <code>make</code>, so if <strong>no</strong> source files change, even
recompiling with MLton is instant (e.g., changing a test and
re-running the tests doesn&rsquo;t require re-building everything).</li>
<li>Symbol also supports scaffolding new Standard ML projects, which is
nicer than starting from scratch.</li>
</ul>


<p>The usage looks something like this:</p>

<pre><code class="bash"># initialize a new project:
‚ùØ symbol-new hello
‚ùØ cd hello

# build with SML/NJ:
‚ùØ ./symbol make
‚ùØ .symbol-work/bin/hello
Hello, world!

# or, build with MLton:
‚ùØ ./symbol make with=mlton
‚ùØ .symbol-work/bin/hello
Hello, world!
</code></pre>

<p>Again, there&rsquo;s way more information <a href="https://github.com/jez/symbol">in the README</a>, so
definitely check it out if you&rsquo;re thinking about setting up a new
Standard ML project.</p>

<h2>Why Standard ML in the first place?</h2>

<p>I&rsquo;ll probably get around to <a href="/surgery-on-code/">writing about <code>multi-grep</code></a> (and related
tools like <code>diff-locs</code> and <code>multi-sub</code>) but at the end of the day:
SML is a really pleasant language to use in a lot of ways:</p>

<ul>
<li>Type inference in Standard ML is a breath of fresh air.</li>
<li>Data types let me wonder less about how things work.</li>
<li>Pattern matching makes for concise, clean, and correct code.</li>
</ul>


<p>Standard ML was my most commonly used programming language throughout
all of my university courses, so there&rsquo;s a definite soft spot in my
heart for it. There are features that I wish it had sometimes, but it&rsquo;s
the only language that I&rsquo;ve used that doesn&rsquo;t feel fundamentally broken
in some way.</p>

<!-- vim:tw=72
-->

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Code Review from the Command Line]]></title>
    <link href="https://blog.jez.io/cli-code-review/"/>
    <updated>2018-01-13T13:14:24-08:00</updated>
    <id>https://blog.jez.io/cli-code-review</id>
    <content type="html"><![CDATA[<p>I do the bulk of my code reviews from the command line, especially when
reviewing larger changes. I&rsquo;ve built up a number of tools and config
settings that help me dig into the nuances of the code I&rsquo;m reviewing, so
that I can understand it better than if I were just browsing online.</p>

<!-- more -->


<p>In particular, I&rsquo;ll walk through how I&hellip;</p>

<ul>
<li>check out the code in the first place,</li>
<li>get a feel for what changed,</li>
<li>visualize the relationships between the files that changed,</li>
<li>bring up the code diffs in Vim,</li>
<li>leverage the unique power of the editor and the terminal.</li>
</ul>


<p>But first, let&rsquo;s talk briefly about the point of code review in the
first place.</p>

<h2>Code review philosophy</h2>

<p>When I ask that other people review my code, it&rsquo;s an opportunity for me
to teach them about the change I&rsquo;ve just made. When I review someone
else&rsquo;s code, it&rsquo;s to learn something from them. Some other benefits of
code review include:</p>

<ul>
<li>Team awareness (to keep a pulse on what else is going on within your
team).</li>
<li>Finding alternative solutions (maybe there&rsquo;s a small change that lets
us kill two birds with one stone).</li>
</ul>


<p>If this is different from how you think about code review, <a href="https://www.youtube.com/watch?v=PJjmw9TRB7s">check out
this talk</a>. Code review is a powerful tool for
learning and growing a team.</p>

<p>With that out of the way, let&rsquo;s dive into the tools I use to maximize
benefit I get from code review.</p>

<h2>Checking out the code</h2>

<p>The first step to reviewing code in the terminal is to check out the
code in the first place. One option is to simply to <code>git pull</code> and then
<code>git checkout &lt;branch&gt;</code>. But if you happen to be using GitHub, we can
get this down to just one command:</p>

<pre><code>hub pr checkout &lt;pr-number&gt;
</code></pre>

<p>It works using <a href="https://github.com/github/hub">hub</a>, which is a tool that exposes various features of
GitHub from the command line. If the pull request is from someone else&rsquo;s
fork, <code>hub</code> is even smart enough to add their fork as a remote and fetch
it.</p>

<h2>At first glance</h2>

<p>With the branch checked out locally, usually my next step is to get a
feel for what changed. For this, I&rsquo;ve written a git alias that shows:</p>

<ul>
<li>which files changed</li>
<li>how many lines changed in each file (additions and deletions)</li>
<li>how many lines changed overall</li>
</ul>


<p><a class="image-link" href="/images/git-stat.png"><img class="fullwidth" src="/images/git-stat.png" title="git stat" ></a></p>

<p>Here&rsquo;s the definition of <code>git stat</code> from my <code>~/.gitconfig</code>:</p>

<pre><code class="bash">[alias]
    # list files which have changed since REVIEW_BASE
    # (REVIEW_BASE defaults to 'master' in my zshrc)
    files = !git diff --name-only $(git merge-base HEAD \"$REVIEW_BASE\")

    # Same as above, but with a diff stat instead of just names
    # (better for interactive use)
    stat = !git diff --stat $(git merge-base HEAD \"$REVIEW_BASE\")
</code></pre>

<p>Under the hood, it just works using <code>git diff</code>, <code>git merge-base</code>, and a
personal environment variable <code>REVIEW_BASE</code>.</p>

<p><code>REVIEW_BASE</code> lets us choose which branch to review relative to. Most of
the time, <code>REVIEW_BASE</code> is <code>master</code>, but this isn&rsquo;t always the case! Some
repos branch off of <code>gh-pages</code>. Sometimes I like to review the most
recent commit as if it were its own branch.</p>

<p>To review the code relative so some other base, set <code>REVIEW_BASE</code> before
running <code>git stat</code>:</p>

<pre><code class="bash"># Review between 'gh-pages' and the current branch
REVIEW_BASE=gh-pages git stat

# Review changes made by the last commit of this branch:
REVIEW_BASE=HEAD^ git stat
</code></pre>

<p>I have <code>export REVIEW_BASE=master</code> in my <code>~/.bashrc</code>, because most
projects branch off of <code>master</code>.</p>

<p>Nothing too crazy yet&mdash;GitHub can already do everything we&rsquo;ve seen so
far. Let&rsquo;s start to up the ante.</p>

<h2>Visualizing file change frequency</h2>

<p>I&rsquo;ve written a short script that shows me a visualization of how
frequently the files involved in this branch change over time:</p>

<p><a class="image-link" href="/images/git-heatmap.png"><img class="fullwidth" src="/images/git-heatmap.png" title="git heatmap" ></a></p>

<p>This command identifies two main things:</p>

<ul>
<li><p><strong>Files with lots of changes</strong>.</p>

<p>Files that have changed a lot in the past are likely to change in the
future. I review these files with an eye towards what the <em>next</em>
change will bring.</p>

<p><em>&ldquo;Is this change robust enough to still be useful in the future?
Will we throw this out soon after merging it?&rdquo;</em></p></li>
<li><p><strong>Files with few changes</strong>.</p>

<p>Files that aren&rsquo;t changed frequently are more likely to be brittle.
Alternatively, it&rsquo;s often the case that infrequently changed files
stay unchanged because the change is better made elsewhere.</p>

<p><em>&ldquo;Does this change challenge an implicit assumption so that some other
part of the code was relying on? Is there a better place for this
change?&rdquo;</em></p></li>
</ul>


<p>Those two commands (<code>git stat</code> and <code>git heatmap</code>) are how I kick off my
code review: getting a birds-eye view of the change and some historical
context for what I&rsquo;m dealing with. Next, I drill down into the
relationships between the files that changed.</p>

<h2>Visualizing relationships between files</h2>

<p>At work I review JavaScript files, so I&rsquo;ve built out this next bit of
tooling specifically for JavaScript.<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup> It helps to understand
which files import others, so I have a command that computes the
dependency graph of the files changed on this branch:</p>

<p><a class="image-link" href="/images/git-depgraph.png"><img class="fullwidth" src="/images/git-depgraph.png" title="git depgraph" ></a></p>

<p>This is where we start to see some distinct advantages over what GitHub
provides. As you see above, the <code>git depgraph</code> alias calculates the
dependency graph for files changed by this branch. Why is this useful?</p>

<ul>
<li><p>Maybe we want to start reviewing from <code>Provider.js</code>, since it doesn&rsquo;t
depend on any other files that have changed.</p></li>
<li><p>Maybe we want to work the other way: start with <code>Elements.js</code> so we
know the motivation for why <code>Provider.js</code> had to changed in the first
place.</p></li>
</ul>


<p>In either case, we can see the structure of the change. Three files
depend on <code>Elements.js</code>, so it&rsquo;s serving the needs of many modules.
<code>Element.js</code> only has one dependency, etc. Each branch&rsquo;s dependency
graph shows different information; it can be surprising what turns up.</p>

<p>I have the <code>git depgraph</code> alias defined like this:</p>

<pre><code class="bash">[alias]
    depgraph = !git madge image --webpack-config webpack.config.js --basedir . --style solarized-dark src
</code></pre>

<p>Some notes about this definition:</p>

<ul>
<li><p>It depends on the <code>git-madge</code> command, which you can <a href="https://github.com/jez/git-madge">download
and install here</a>.</p></li>
<li><p>It&rsquo;s using <em>this project&rsquo;s</em> <code>webpack.config.js</code> file, so I&rsquo;ve made
this alias local to the repo, rather than available globally.</p></li>
<li><p>It dumps the image to stdout. Above, we used iTerm2&rsquo;s <a href="https://iterm2.com/documentation-images.html">imgcat</a>
program to pipe stdin and dump a raster image to the terminal.</p>

<p>If you don&rsquo;t use iTerm2 or don&rsquo;t want to install <code>imgcat</code>, you can
pipe it to Preview using open<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup> (<code>open -f -a Preview</code>) or just
redirect the PNG to a file.</p></li>
</ul>


<p>The <code>git depgraph</code> alias is a game changer. It makes it easier to get spun
up in new code bases, helps make sense of large changes, and just looks
plain cool. But at the end of the day, we came here to review some code,
so let&rsquo;s take a look at how we can actually view the diffs of the files
that changed.</p>

<h2>Reviewing the diffs</h2>

<p>To review the diffs, the simplest option is to just run <code>git diff
master..HEAD</code>. This has a bunch of downsides:</p>

<ul>
<li><p>No syntax highlighting (everything is either green or red).</p></li>
<li><p>No surrounding context (for example, GitHub lets you click to expand
lines above or below a diff hunk).</p></li>
<li><p>The diff is &ldquo;unified,&rdquo; instead of split into two columns.</p></li>
<li><p>No way to exclude a specific file (the 300 line diff to your
<code>yarn.lock</code> file is sometimes nice to hide).</p></li>
</ul>


<p>My solution to all of these problems is to view the diffs in Vim, with
the help of two Vim plugins and two git aliases. Before we get to
that, here&rsquo;s a screenshot:</p>

<p><a class="image-link" href="/images/git-review.png"><img class="fullwidth" src="/images/git-review.png" title="git review" ></a></p>

<p>Looks pretty similar to GitHub&rsquo;s interface, with the added bonus that
it&rsquo;s using my favorite colorscheme! The Vim plugins featured are:</p>

<ul>
<li><a href="https://github.com/tpope/vim-fugitive">tpope/vim-fugitive</a> for showing the side-by-side diff (<code>:Gdiff</code>).</li>
<li><a href="https://github.com/airblade/vim-gitgutter">airblade/vim-gitgutter</a> for showing the <code>+/-</code> signs.</li>
<li><a href="https://github.com/jez/vim-colors-solarized">jez/vim-colors-solarized</a> for tweaking the diff highlight
colors.<sup id="fnref:3"><a href="#fn:3" rel="footnote">3</a></sup></li>
</ul>


<p>And to orchestrate the whole thing, I&rsquo;ve set up these two aliases:</p>

<pre><code class="bash">[alias]
  # NOTE: These aliases depend on the `git files` alias from
  # a few sections ago!

    # Open all files changed since REVIEW_BASE in Vim tabs
    # Then, run fugitive's :Gdiff in each tab, and finally
    # tell vim-gitgutter to show +/- for changes since REVIEW_BASE
    review = !vim -p $(git files) +\"tabdo Gdiff $REVIEW_BASE\" +\"let g:gitgutter_diff_base = '$REVIEW_BASE'\"

    # Same as the above, except specify names of files as arguments,
    # instead of opening all files:
    # git reviewone foo.js bar.js
    reviewone = !vim -p +\"tabdo Gdiff $REVIEW_BASE\" +\"let g:gitgutter_diff_base = '$REVIEW_BASE'\"
</code></pre>

<p>Here&rsquo;s how they work:</p>

<ul>
<li><p><code>git review</code> opens each file changed by this branch as a tab in Vim.
Then <code>:Gdiff</code> from vim-fugitive shows the diff in each tab.</p></li>
<li><p><code>git reviewone</code> is like <code>git review</code>, but you specify which
files to open (in case you only want to diff a few).</p></li>
</ul>


<p>Like with the <code>git stat</code> alias, these aliases respect the <code>REVIEW_BASE</code>
environment variable I&rsquo;ve set up in my <code>~/.bashrc</code>. (Scroll back up for
a refresher.) For example, to review all files relative to <code>master</code>:</p>

<pre><code class="bash">REVIEW_BASE=master git review
</code></pre>

<p>At this point, you might think that all we&rsquo;ve done is re-create the
GitHub code review experience in Vim. But actually what we&rsquo;ve done is so
much more powerful.</p>

<h2>Interactive Code Review</h2>

<p>When reviewing on GitHub, the code is completely static&mdash;you can&rsquo;t
change it. Also, because the code is coming from GitHub&rsquo;s servers,
it&rsquo;s laggy when you click around to view related files. By switching our
code review to the terminal, we can now edit files, jump to other files,
and run arbitrary commands at no cost.</p>

<p>It might not be obvious how huge of a win this is, so let&rsquo;s see some
examples. Take this screenshot of the <code>requireElement</code> function. It
moved from <em>above</em> the <code>findElement</code> function to <em>below</em> it (probably
because the former calls the latter):</p>

<p><a class="image-link" href="/images/requireElement01.png"><img class="fullwidth" src="/images/requireElement01.png" title="diff" ></a></p>

<p>But is the location of the <code>requireElement</code> function the only thing
that&rsquo;s changed? By editing the file to move the function back to its
original location, vim-fugitive will automatically recompute the diff.
And in fact, we can see that the <em>type of the argument</em> has changed too,
from <code>string</code> to <code>ElementType</code>:</p>

<p><a class="image-link" href="/images/requireElement02.png"><img class="fullwidth" src="/images/requireElement02.png" title="diff" ></a></p>

<p>If we had been viewing this on GitHub, we might have taken for granted
that the function didn&rsquo;t change. But since we&rsquo;re in our editor, we can
interactively play around with our code and discover things we might
have missed otherwise. The advantages of interactive code review go well
beyond this example:</p>

<ul>
<li><p>In a Flow project, we can ask for the type of a variable.</p></li>
<li><p>In a test file, we can change the test and see if it still passes or
if it now fails.</p></li>
<li><p>We can <code>grep</code> the project for all uses of a function (including files
<em>not</em> changed by this branch).</p></li>
<li><p>We can open up related files for cross-referencing.</p></li>
<li><p>We can run the code in a debugger and see how it behaves.</p></li>
</ul>


<p>By having the full power of our editor, we can literally retrace the
steps that the author went through to create the pull request. If our
goal is to understand and learn from code review, there&rsquo;s no better way
than walking in the author&rsquo;s shoes.</p>

<h2>Recap</h2>

<p>To recap, here&rsquo;s a list of the tools I use to review code at the command
line:</p>

<ul>
<li><code>hub pr checkout</code></li>
<li><code>git stat</code> to list files that have changed</li>
<li><code>git heatmap</code> to show how frequently these files change</li>
<li><code>git depgraph</code> to show a graph of which files depend on which</li>
<li><code>git review</code> to open diffs of all the files in Vim</li>
<li><code>git reviewone</code> to open diffs for a specific handful of files</li>
</ul>


<p>If you&rsquo;re having trouble incorporating any of these into your workflow,
feel free to reach out and let me know! I&rsquo;m happy to help.</p>

<!-- vim:tw=72
-->

<div class="footnotes">
<hr/>
<ol>
<li id="fn:1">
<p>The techniques here apply to any language that you can statically analyze. In particular, I have a rough prototype of everything JavaScript-specific you see here that works with Standard ML instead. If you can find me the dependency information for your favorite language, I&rsquo;d be happy to help you turn it into a visualization.<a href="#fnref:1" rev="footnote">&#8617;</a></p></li>
<li id="fn:2">
<p>The <code>open</code> command is macOS-specific. On Linux, you might want to look at the <code>display</code> command from ImageMagick.<a href="#fnref:2" rev="footnote">&#8617;</a></p></li>
<li id="fn:3">
<p>I&rsquo;ve patched the default Solarized colors for Vim so that lines retain their syntax highlighting in the diff mode, while the backgrounds are highlighted. You can see how this works in this commit: <a href="https://github.com/jez/vim-colors-solarized/commit/bca72cc">https://github.com/jez/vim-colors-solarized/commit/bca72cc</a><a href="#fnref:3" rev="footnote">&#8617;</a></p></li>
</ol>
</div>

]]></content>
  </entry>
  
</feed>
